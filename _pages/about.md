---
permalink: /
title: "Yung-Sung Chuang"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am now an undergraduate student in Electrical Engineering at National Taiwan University. My research interest broadly covers the deep learning technique for natural language processing and speech processing. In particular, I aim to utilize the ability of machines to help people grasp large information in text/audio form in efficient ways. Towards this goal, I joined Speech Processing Lab supervised by [Hung-Yi Lee](http://speech.ee.ntu.edu.tw/~tlkagk/index.html) and Machine Intelligence Understanding Lab supervised by [Yun-Nung (Vivian) Chen](https://www.csie.ntu.edu.tw/~yvchen/). I received the NTU Presidential Award for top 5% students four times in 2018-2020, [Irving T. Ho Memorial Scholarship](https://irvingthofoundation.github.io/ho-fellows.htm) in 2018 and 2019. Here is my [Curriculum Vitae](/CV/CV.pdf).

I will share some notes or articles during my study in my [blog](https://voidism.github.io). Thanks for reading and taking the time to comment :)

Publications
===

$^\dagger$ indicates equal contribution.



<table>

<tr>
    <td><img src="https://i.imgur.com/nuT5c51.png" alt="L2KD" width="300"></td>
    <td style="font-size: 17px; line-height: 1.4em;">
<a href="https://arxiv.org/abs/2010.13826">Semi-Supervised Spoken Language Understanding via Self-Supervised Speech and Language Model Pretraining</a><br/> Cheng-I Lai, <strong>Yung-Sung Chuang</strong>, Hung-Yi Lee, Shang-Wen Li, James Glass. <br/><i>Under review in ICASSP 2021; arXiv Preprint <a href="https://arxiv.org/abs/2010.13826">https://arxiv.org/abs/2010.13826</a></i></td>
</tr>
<tr>
    <td><img src="https://i.imgur.com/a71dNjj.png" alt="L2KD" width="300"></td>
    <td style="font-size: 17px; line-height: 1.4em;">
<a href="https://arxiv.org/abs/2010.02123">Lifelong Language Knowledge Distillation</a><br/> <strong>Yung-Sung Chuang</strong>, Shang-Yu Su, Yun-Nung Chen. <br/><i>Accepted by EMNLP 2020 conference; arXiv Preprint <a href="https://arxiv.org/abs/2010.02123">https://arxiv.org/abs/2010.02123</a></i></td>
</tr>
<tr>
    <td><img src="https://i.imgur.com/5bMe55S.png" alt="DualInf" width="300"></td>
    <td style="font-size: 17px; line-height: 1.4em;">
<a href="https://arxiv.org/abs/2010.04246">Dual Inference for Improving Language Understanding and Generation</a><br/> <strong>Yung-Sung Chuang<sup>&#8224;</sup></strong>,  Shang-Yu Su<sup>&#8224;</sup>, Yun-Nung Chen. <br/><i>Accepted by Findings of EMNLP 2020; arXiv Preprint <a href="https://arxiv.org/abs/2010.04246">https://arxiv.org/abs/2010.04246</a></i></td>
</tr>
<tr>
    <td><img src="https://i.imgur.com/Lbw7MIT.png" alt="MDS" width="300"></td>
    <td style="font-size: 17px; line-height: 1.4em;">
<a href="https://arxiv.org/abs/2004.09205">A Study of Cross-Lingual Ability and Language-specific Information in Multilingual BERT</a><br/>Chi-Liang Liu<sup>&#8224;</sup>, Tsung-Yuan Hsu<sup>&#8224;</sup>, <strong>Yung-Sung Chuang<sup>&#8224;</sup></strong>, Hung-Yi Lee. <br/><i>arXiv Preprint <a href="https://arxiv.org/abs/2004.09205">https://arxiv.org/abs/2004.09205</a></i></td>
</tr>
<tr>
    <td><img src="https://i.imgur.com/I4fA5uK.png" alt="SpeechBERT" width="300"></td>
    <td style="font-size: 17px; line-height: 1.4em;">
<a href="https://arxiv.org/abs/1910.11559">SpeechBERT: An Audio-and-text Jointly Learned Language Model for End-to-end Spoken Question Answering</a><br/> <strong>Yung-Sung Chuang</strong>, Chi-Liang Liu, Hung-Yi Lee, Lin-shan Lee. <br/><i>Accepted by Interspeech 2020; arXiv Preprint <a href="https://arxiv.org/abs/1910.11559">https://arxiv.org/abs/1910.11559</a></i><br/> <strong>This work won Interspeech 2020 Travel Grant.</strong></td>
</tr>
<tr>
    <td><img src="https://i.imgur.com/sTKvjNv.png" alt="RCT-Gen" width="300"></td>
    <td style="font-size: 17px; line-height: 1.4em;"><a href="https://www.aclweb.org/anthology/D19-6214.pdf">Towards Understanding of Medical Randomized Controlled Trials by Conclusion Generation</a> <br/> Alexander Te-Wei Shieh<sup>&#8224;</sup>, <strong>Yung-Sung Chuang<sup>&#8224;</sup></strong>, Shang-Yu Su, Yun-Nung Chen.<br/> In <i>Proceedings of the 10th International Workshop on Health Text Mining and Information Analysis at EMNLP (LOUHI 2019) </i></td>
</tr>
</table>

  
   

Short Talks (in Mandarin)
===
## [Non-Autoregressive Conditional Sequence Modeling](https://www.youtube.com/embed/jvyKmU4OM3c)
<iframe width="560" height="315" src="https://www.youtube.com/embed/jvyKmU4OM3c" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

## [Unsupervised Syntactic Parsing](https://www.youtube.com/watch?v=YIuBHB9Ejok)
<iframe width="560" height="315" src="https://www.youtube.com/embed/YIuBHB9Ejok" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

             
               
  
Virtual Conference Videos (in English)
===
## [\[INTERSPEECH 2020\] SpeechBERT: An Audio-and-text Jointly Learned Language Model for End-to-end Spoken Question Answering](https://www.youtube.com/watch?v=a6txVSmX7fI)
<iframe width="560" height="315" src="https://www.youtube.com/embed/a6txVSmX7fI" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

## [\[EMNLP 2020\] Lifelong Language Knowledge Distillation](https://www.youtube.com/watch?v=t3Ee5fA8mCo)
<iframe width="560" height="315" src="https://www.youtube.com/embed/t3Ee5fA8mCo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

  
  
             
               
  
  
Teaching
===

**Teaching Assistant**, *Deep Learning for Human Language Processing, 2020 Spring* (Prof, Hung-Yi Lee)

  

Current Research Topics
===

- Natural Language Genration: [Text Style Transfer (GAN-based)](https://github.com/voidism/Transformer_CycleGAN_Text_Style_Transfer-pytorch)/[(Delete-Insert-based)](https://github.com/voidism/Insert-Delete-TextStyleTransfer), [Conclusion Generation for Medical RCTs](https://arxiv.org/abs/1910.01462)
- Cross-Modal Language Representations for Text and Speech: [in unsupervised setting](https://docs.google.com/presentation/d/1FWit7TqILpk4ZrcOZ08hV8xuQCdqHub3_xz0vUEWTGY/edit?usp=sharing) / [in supervised settings to solve Spoken Question Answering](https://arxiv.org/abs/1910.11559)
- Non-autoregressive model for Speech-to-Text Translation (in progress)
- Knowledge Distillation & Lifelong learning (in progress)

Projects
===
<table>
<tr>
    <td><img src="https://i.imgur.com/AQTfGQb.png" alt="MIPS" width="300"></td>
    <td style="font-size: 17px; line-height: 1.4em;">
<a href="https://drive.google.com/file/d/199N-2Up1SFS_BtM_nRVw8yCiYuepw1bg/view">Speech Recognition for Impaired Speaker</a><br/><strong>Yung-Sung Chuang</strong>, Tsai-Lun Yang, Che-Ruei Hsu, Liang-Yuan Wu. <br/>Final Project in <i>Introduction to Biomedical Engineering 2020 Spring</i><br/>Reducing WER from 80% to 20% for patient voice via personalized adaptation (in Mandarin).</td>
</tr>
<tr>
    <td><img src="https://i.imgur.com/qR8Wzn1.png" alt="NMLAB" width="300"></td>
    <td style="font-size: 17px; line-height: 1.4em;">
<a href="https://github.com/bchao1/108-2-NMLAB-Final">DPP: Decentralized Publishing Platform</a><br/><strong>Yung-Sung Chuang</strong>, Chung-Hao Chao, Siang-Ruei Wu. <br/>Final Project in <i>Networking and Multinmedia Lab 2020 Spring</i><br/>A Decentralized Publishing Platform created with Blockchain and Etheruem smart contract.</td>
</tr>
<tr>
    <td><img src="https://i.imgur.com/IZNIKYr.png" alt="MIPS" width="300"></td>
    <td style="font-size: 17px; line-height: 1.4em;">
<a href="https://github.com/w4n9r3ntru3/MIPS-Processor">Single-Cycle MIPS Processor Implementation in Verilog</a><br/><strong>Yung-Sung Chuang</strong>, Ren-Chu Wang. <br/>Final Project in <i>Computer Architecture 2019 Fall</i><br/>Ranking 2nd place out of 44 groups by A*T value (Area x Clock Time)</td>
</tr>
<tr>
    <td><img src="https://i.imgur.com/cSgAOjI.png" alt="ICCAD" width="300"></td>
    <td style="font-size: 17px; line-height: 1.4em;">
<a href="https://github.com/raywu0123/ICCAD2019-Problem-E">Rectilinear Polygon Operations for Physical Design</a><br/>Siang-Ruei Wu, <strong>Yung-Sung Chuang</strong>.<br/>Final Project in <i>Algorithms 2019 Spring</i><br/>ICCAD 2019 CAD Contest - Problem E (<a href="http://iccad-contest.org/2019/tw/problems.html">competition website</a>)</td>
</tr>
<tr>
    <td><img src="https://i.imgur.com/oJ7bwsx.png" alt="MDDA" width="300"></td>
    <td style="font-size: 17px; line-height: 1.4em;">
<a href="https://voidism.github.io/pdfs/2019_DLCV_Final_Project_Poster_(final).pdf">Multi-Source Unsupervised Domain Adaptation Challenge</a><br/><strong>Yung-Sung Chuang</strong>, Chen-Yi Lan, Hung-Ting Chen, Chang-Le Liu. <br/>Final Project in Deep Learning for <i>Computer Vision 2019 Spring</i></td>
</tr>
<tr>
    <td><img src="https://i.imgur.com/rJVZ9pc.png" alt="CycleGAN" width="300"></td>
    <td style="font-size: 17px; line-height: 1.4em;">
<a href="https://github.com/voidism/Transformer_CycleGAN_Text_Style_Transfer-pytorch">Transformer-based CycleGAN Text Style Transfer</a><br/><strong>Yung-Sung Chuang</strong>. <br/>Research Project in 2018 Fall</td>
</tr>
<tr>
    <td><img src="https://i.imgur.com/DaR48di.png" alt="PyWordSeg" width="300"></td>
    <td style="font-size: 17px; line-height: 1.4em;">
<a href="https://arxiv.org/abs/1901.05816">Robust Chinese Word Segmentation with Contextualized Word Representations</a><br/><strong>Yung-Sung Chuang</strong>. <br/>ArXiv Link: <a href="https://arxiv.org/abs/1901.05816">https://arxiv.org/abs/1901.05816</a><br/>Pypi Link: <a href="https://pypi.org/project/pywordseg/">https://pypi.org/project/pywordseg/</a><br/>Final project in <i>Digital Signal Processing 2018 Fall</i></td>
</tr>
<tr>
    <td><img src="https://i.imgur.com/ZMwm99W.png" alt="BiParser" width="300"></td>
    <td style="font-size: 17px; line-height: 1.4em;">
<a href="https://github.com/voidism/BiLSTM_Collocation_Parser">BiLSTM Collocation Parser</a><br/><strong>Yung-Sung Chuang</strong>. <br/>Intern work in <i>Acadamia Sinica, 2018 Fall</i></td>
</tr>
<tr>
    <td><img src="https://i.imgur.com/fCFiqu6.png" alt="MTRS" width="300"></td>
    <td style="font-size: 17px; line-height: 1.4em;">
<a href="https://voidism.github.io/project/2018/07/06/Some-Baseline-Methods-for-Multi-Turn-Response-Selection/">Chinese Multi Turn Response Selection</a><br/><strong>Yung-Sung Chuang</strong>, Hsing-Chien Wang, Yi-Ting Hsieh. <br/>Final Project in <i>Machine Learning 2018 Spring</i></td>
</tr>
<tr>
    <td><img src="https://i.imgur.com/URLbmf1.png" alt="MTRS" width="300"></td>
    <td style="font-size: 17px; line-height: 1.4em;">
<a href="https://github.com/voidism/Big-Two">Big Two Game Environment and Agent in C++</a><br/><strong>Yung-Sung Chuang</strong>, Hsin Cheng. <br/>Final Project in <i>Computer Programming 2017 Fall</i></td>
</tr>
</table>

Honors
===
- **Dean's list (4 times)**, Electrical Engineering Dept. at NTU, *Spring ’18, Spring ’19, Fall ’19, Spring ’20*
- **Irving T. Ho Memorial Scholarship (2 times)**, EECS at NTU, *Fall ’18, Fall ’19*
- **Travel Grant**, INTERSPEECH 2020 conference, *Sep. 2020*
- **Appier Best Application Award**, 2020 NTU CSIE Undergrad Special Research Exhibition, *Jun. 2020*
- **2nd Place & Appier 1st Award**, 2019 NTU CSIE Undergrad Special Research Exhibition, *Jun. 2019*
- **2nd Place**, 2019 NTUEE Undergraduate Innovation Award, *Jun. 2019*
- **1st Place**, 2018 H. Spectrum Demo Day (out of 21 teams), *Jul. 2018*
- **1st Place**, NCTS Health Hackathon 2018 (out of 18 teams), *Jun. 2018*
- **Top 8 Finalist**, Microsoft Imagine Cup Taiwan National Final 2018, *Apr. 2018*
- **Best Tech Award & Microsoft Enterprise Award**, MakeNTU 2018 (out of 50 teams), *Mar. 2018*
- **1st place of Dept. of Transportation**, HackNTU 2017 (out of 100+ teams), *Jul. 2017*


Competitions
===
## NCTS Health Hackathon 2018
*1st Placewith NT$120,000 (out of 18 teams)* \[[News](https://www.ctimes.com.tw/DispNews-tw.asp?O=HK259B39BE2SAA00N9), [Certificate](https://voidism.github.io/img/NCTS_certificate.jpg)\]
- A hackathon on organized byNational Center for Theoretical Sciences and Mount Sinai Health System, New York.
- Proposed an improved system for doctors shifting in hospital — PRO (Patient Relay Optimizer) to help doctors grasp all infoabout patients, status, tasks at a glance, reducing the risk of information shifting incompletely.
- Won the 1st place of 2018 H. Spectrum Demo Day (out of 21 teams) \[[News](https://www.bnext.com.tw/article/49900/h.-spectrum-demoday-foxcon)\]

## MakeNTU 2018
*Best Tech Award with NT$50,000 & Microsoft Enterprise Award (out of 50 teams)* \[[Photo](https://goo.gl/wa5LPz)\]
- A hackathon focus on the combination of hardware and software, organized by NTU
- Built an automatic machine for picking good coffee beans with deep learning technique.
- Placed intop 8in the finalist of Microsoft Imagine Cup Taiwan National Final 2018.

## HackNTU 2017
*1st Place of Department of Transportation with NT$50,000 (out of 100+ teams)* \[[Photo](https://goo.gl/tEpX7X)\]
- Built asmart bus bell system for solving the problems of getting on the right bus in the huge and busy city.
- Exhibited on WCIT 2017 (World Congresson Information Technology).